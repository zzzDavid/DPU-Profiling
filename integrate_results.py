"""
This file is to integrate the power results of OFA blocks
with the latency results generated by aw_nas
"""
import copy
import csv
import os
import yaml
import json

def read_latency(path="./profiled_nets"):

    # get all yamls
    yamls = list()
    for net in os.listdir(path):
        _curdir = os.path.join(path, net)
        for file in os.listdir(_curdir):
            if file.endswith('.yaml'):
                yamls.append(os.path.join(_curdir, file))
    # read all primitives
    blocks = list()
    for y in yamls:
        with open(y, 'r') as f:
            tmp = yaml.load(f)
            blocks.extend(tmp['primitives'])

    # print blocks
    # for b in blocks:
    #     print(b)

    return blocks


def calc_energy(source='./source', csvdir='./results_csv', stack_latency=dict()):
    """
    1. get all energy results from csv dir
    2. according to those names, get the block information from source dir
    3. match those blocks with their energy results
    """

    # get all energy results form csv dir
    # let's use VCC int
    power_dict = dict() # key=filename, value=avg power
    for c in os.listdir(csvdir):
        _file = os.path.join(csvdir, c)
        VCC_INT=[]
        with open(_file, newline='') as csvfile:
            lines = csv.reader(csvfile, delimiter=',')
            for i, line in enumerate(lines):
                if i==0: continue
                VCC_INT.append(int(line[1]))
            power_dict[c.replace('.csv','')] = sum(VCC_INT) / len(VCC_INT)
    # let's check power dict
    # for k, v in power_dict.items():
    #    print(f"{k} : {v}")

    energy_results = list()
    for name, power_value in power_dict.items():
        block_info_file = os.path.join(source, name + '.json')
        with open(block_info_file, 'r') as f:
            block_info = json.load(f)
            yaml_dict = dict()
            yaml_dict['C'] = block_info['mobile_inverted_conv']['in_channels']
            yaml_dict['C_out'] = block_info['mobile_inverted_conv']['out_channels']
            yaml_dict['affine'] = True
            yaml_dict['expansion'] = block_info['mobile_inverted_conv']['expand_ratio']
            yaml_dict['kernel_size'] = block_info['mobile_inverted_conv']['kernel_size']
            yaml_dict['prim_type'] = 'mobilenet_v2_block'
            yaml_dict['spatial_size'] = None
            yaml_dict['stride'] = block_info['mobile_inverted_conv']['stride']
            yaml_dict['power'] = power_value
            yaml_dict['latency'] = stack_latency[name]

            energy_results.append(yaml_dict)
    return energy_results


def stack_latency_results(path='./latency'):
    """
    we should also include the latency results
    generated while measuring power
    """
    # let's get a OrderedDict str(blockname) : float
    # to store layer latency results!
    from collections import OrderedDict
    import re

    latency_dict = OrderedDict()  # integer : list()
    for txt_file in os.listdir(path):
        block_name = txt_file.replace('.txt', '')
        _file = os.path.join(path, txt_file)
        print("processing: " + _file)
        block_latency = OrderedDict() # stores the layer latency results for this net
        with open(_file, 'r') as f:
            lines = f.readlines()
            # read all layer's latency for many runs
            # same layer's latency stored in a list
            for line in lines:
                line = re.split(r"\s+", line)
                line = [s for s in line if s != '']
                if not (len(line) > 4 and re.match(r"\d+", line[0])): continue
                layer_id = int(line[0])
                node_name = line[1]
                latency = float(line[4])
                if node_name.endswith('conv_1') or \
                    node_name.endswith('new') or  \
                    node_name.endswith('fc'): continue
                if layer_id not in block_latency.keys():
                    block_latency[layer_id] = list()
                block_latency[layer_id].append(latency)
            # after reading all lines, we have all layer's latency for many runs
            # average across many runs
            for layer_id, latency in block_latency.items():
                avg_latency = sum(latency) / len(latency)
                block_latency[layer_id] = avg_latency
            # sum layer latency to block latency
            latency_dict[block_name] = sum(block_latency.values()) / 50
    return latency_dict


def match(latency_results, energy_results):

    for l in latency_results:
        for e in copy.deepcopy(energy_results):
            if l['C'] != e['C']: continue
            if l['C_out'] != e['C_out']: continue
            if l['expansion'] != e['expansion']: continue
            if l['stride'] != e['stride']: continue

            l['power'] = e['power']
            l['latency'] = e['latency']
            energy_results.remove(e)

    for e in energy_results:
        latency_results.append(e)

    for l in latency_results:
        l['performances'] = dict()
        if 'latency' in l.keys():
            l['performances']['latency'] = l['latency']
            l.pop('latency')
        if 'power' in l.keys():
            l['performances']['power'] = l['power']
            l.pop('power')

    return latency_results


if __name__ == "__main__":
    latency_results = read_latency()
    latency_results_while_power_measuring = stack_latency_results()
    power_results = calc_energy(stack_latency=latency_results_while_power_measuring)
    combined = match(latency_results, power_results)

    with open('profiled_blocks.yaml', 'w') as f:
        yaml.safe_dump(combined, f)